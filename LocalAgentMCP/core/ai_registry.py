import os
import json
import logging
from typing import Dict, Any

# Provider í´ë˜ìŠ¤ë“¤ì´ ìˆë‹¤ê³  ê°€ì • (ê¸°ì¡´ êµ¬ì¡° ìœ ì§€)
from .providers.ollama_provider import OllamaProvider
from .providers.lmstudio_provider import LMStudioProvider
from .providers.comfyui_provider import ComfyUIProvider

logger = logging.getLogger(__name__)

# -------------------------------------------------------------
# Load Configuration
# -------------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
REGISTRY_PATH = os.path.join(BASE_DIR, "ai_registry.json")
CHARACTERS_DIR = os.path.join(BASE_DIR, "characters")

def load_config() -> Dict[str, Any]:
    config = {}
    
    # 1. Load Base Registry
    if os.path.exists(REGISTRY_PATH):
        with open(REGISTRY_PATH, "r", encoding="utf-8") as f:
            config = json.load(f)
    else:
        logger.error(f"ai_registry.json not found: {REGISTRY_PATH}")

    # 2. Load Character Details
    if os.path.isdir(CHARACTERS_DIR):
        for filename in os.listdir(CHARACTERS_DIR):
            if filename.endswith(".json"):
                char_name = filename[:-5] # remove .json
                try:
                    with open(os.path.join(CHARACTERS_DIR, filename), "r", encoding="utf-8") as f:
                        char_data = json.load(f)
                        
                        # Merge into config['characters']
                        if "characters" not in config:
                            config["characters"] = {}
                        
                        # Existing config (from ai_registry.json) takes precedence for connection info,
                        # but we enrich it with prompts from the character file.
                        if char_name in config["characters"]:
                            config["characters"][char_name].update(char_data)
                        else:
                            # If not in registry but file exists, add it (assuming default provider)
                            char_data["provider"] = char_data.get("provider", "ollama") # Default
                            char_data["model"] = char_data.get("base_model", "qwen2.5-coder:14b")
                            config["characters"][char_name] = char_data
                            
                except Exception as e:
                    logger.error(f"Failed to load character {filename}: {e}")

    return config

# Load once on module import
config = load_config()

# -------------------------------------------------------------
# Provider Factory
# -------------------------------------------------------------
def get_provider(provider_name: str):
    """Return provider instance by name"""
    name = provider_name.lower()
    if name == "ollama": return OllamaProvider()
    if name == "lmstudio": return LMStudioProvider()
    if name == "comfyui": return ComfyUIProvider()
    raise Exception(f"Unsupported provider: {provider_name}")

# -------------------------------------------------------------
# Public API â€” Local AI Unified Interface
# -------------------------------------------------------------
class AIRegistry:

    @staticmethod
    def reload():
        """Reload configuration from disk"""
        global config
        config = load_config()
        logger.info("AI Registry Reloaded")

    @staticmethod
    def call_llm(prompt: str, system: str = "", character_name: str = "mia"):
        """
        í†µí•© í…ìŠ¤íŠ¸ ìƒì„± (ìºë¦­í„° ì´ë¦„ìœ¼ë¡œ í˜¸ì¶œ)
        ê¸°ë³¸ê°’: mia (ì½”ë”© ë‹´ë‹¹)
        """
        # 1. ìºë¦­í„° ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        char_config = config.get("characters", {}).get(character_name)
        
        # ì˜¤íƒ€ë‚˜ ì„¤ì • ëˆ„ë½ ì‹œ 'ë¯¸ì•„'ë¥¼ ê¸°ë³¸ìœ¼ë¡œ
        if not char_config:
            logger.warning(f"Character '{character_name}' not found. Fallback to 'mia'.")
            char_config = config.get("characters", {}).get("mia")

        if not char_config:
            return "[System Error] ai_registry.jsonì— 'mia' ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤."

        # 2. ì •ë³´ ì¶”ì¶œ
        provider_name = char_config.get("provider", "ollama")
        model = char_config.get("model", char_config.get("base_model", "qwen2.5-coder:14b"))
        
        # 3. System Prompt ë³‘í•©
        # ìºë¦­í„° ê³ ìœ  í”„ë¡¬í”„íŠ¸ê°€ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ê¸°ë³¸ìœ¼ë¡œ ì‚¬ìš©
        char_system_prompt = char_config.get("system_prompt", "")
        
        final_system = char_system_prompt
        if system:
            # í˜¸ì¶œ ì‹œ ì „ë‹¬ëœ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ê°€ ìˆë‹¤ë©´ ì¶”ê°€ (ë˜ëŠ” ë®ì–´ì“°ê¸° ì •ì±… ê²°ì •)
            # ì—¬ê¸°ì„œëŠ” ë’¤ì— ë§ë¶™ì´ëŠ” ë°©ì‹ìœ¼ë¡œ ì²˜ë¦¬
            final_system = f"{char_system_prompt}\n\n[Additional Instructions]\n{system}"

        # 4. Provider í˜¸ì¶œ
        try:
            provider = get_provider(provider_name)
            logger.info(f"ğŸ¤– AI Call: [{character_name.upper()}] using [{model}]")
            return provider.generate_text(prompt=prompt, system=final_system, model=model)
        except Exception as e:
            return f"[Error] AI Call Failed: {e}"

    @staticmethod
    def call_vision(image_path: str, prompt: str, model_key: str = "primary"):
        vision_cfg = config.get("vision", {})
        if model_key not in vision_cfg: return "[Error] Vision config not found"
        target = vision_cfg[model_key]
        provider = get_provider(target["provider"])
        return provider.analyze_image(image_path=image_path, prompt=prompt, model=target["model"])

    @staticmethod
    def generate_image(prompt: str, workflow: str = None, model_key: str = "diffusion"):
        image_cfg = config.get("image", {})
        if model_key not in image_cfg: return "[Error] Image config not found"
        target = image_cfg[model_key]
        provider = get_provider(target["provider"])
        final_workflow = workflow or target.get("workflow")
        return provider.generate_image(prompt=prompt, workflow=final_workflow)